{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from progressbar import ProgressBar\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import pycountry\n",
    "import jellyfish\n",
    "import difflib\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('entities_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    " \n",
    "def fuzzy_match(s1, s2, max_dist=.8):\n",
    "    return jellyfish.jaro_distance(s1, s2) >= max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_names = [i.name.lower() for i in pycountry.countries]\n",
    "\n",
    "\n",
    "def title_except(s, exceptions=['a', 'an', 'of', 'the', 'is']):\n",
    "    word_list = re.split(' ', s)       #re.split behaves as expected\n",
    "    final = [word_list[0].capitalize()]\n",
    "    for word in word_list[1:]:\n",
    "        final.append(word in exceptions and word or word.capitalize())\n",
    "    return \" \".join(final)\n",
    "\n",
    "\n",
    "def correct_country_mispelling(s):\n",
    "    with open(\"ISO3166ErrorDictionary.csv\", \"rb\") as info:\n",
    "        reader = csv.reader(info)\n",
    "        for row in reader:\n",
    "            if s.lower() == unicode(row[0],'utf8').lower():\n",
    "                return row[2]\n",
    "            if s.lower() == unidecode(row[0]).lower():\n",
    "                return row[2]\n",
    "            if s.lower() == remove_non_ascii(row[0]).lower():\n",
    "                return row[2]\n",
    "    return s\n",
    "\n",
    "\n",
    "def matching_countries(entity):\n",
    "    # further correction for misspellings\n",
    "    matching_countries = difflib.get_close_matches(entity, country_names, cutoff=0.8,)\n",
    "    if matching_countries:\n",
    "        confidence = difflib.SequenceMatcher(None, matching_countries[0], entity).ratio()\n",
    "        return (matching_countries[0], confidence)\n",
    "\n",
    "    \n",
    "def get_countries(places, spellcheck=False):\n",
    "    # correcting selling introduces some false positives\n",
    "    # likelihood of official government documents being spelled incorrectly is low\n",
    "    countries = []\n",
    "    for place, label in places:\n",
    "        if label == 'LOCATION':\n",
    "            place = correct_country_mispelling(place)\n",
    "            if spellcheck:\n",
    "                match = matching_countries(place.lower())\n",
    "                if match:\n",
    "                    countries.append((place, match[1]))\n",
    "            else:\n",
    "                if place.lower() in country_names:\n",
    "                    countries.append((place, 1.0))\n",
    "    c = set(Counter(name for name, _ in countries).iteritems())\n",
    "    c_dict = {}\n",
    "    for country, count in c:\n",
    "        # gets the probability from before the counter\n",
    "        c_dict.update({country: {'probability': probability, 'count': count} for name, probability in sorted(countries) if name in country})\n",
    "    return c_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoname_id</th>\n",
       "      <th>continent_code</th>\n",
       "      <th>continent_name</th>\n",
       "      <th>country_iso_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>subdivision_iso_code</th>\n",
       "      <th>subdivision_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>metro_code</th>\n",
       "      <th>time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861060</td>\n",
       "      <td>AS</td>\n",
       "      <td>Asia</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia/Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1809858</td>\n",
       "      <td>AS</td>\n",
       "      <td>Asia</td>\n",
       "      <td>CN</td>\n",
       "      <td>China</td>\n",
       "      <td>44</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Guangzhou</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1850147</td>\n",
       "      <td>AS</td>\n",
       "      <td>Asia</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>13</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia/Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1814991</td>\n",
       "      <td>AS</td>\n",
       "      <td>Asia</td>\n",
       "      <td>CN</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2077456</td>\n",
       "      <td>OC</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geoname_id continent_code continent_name country_iso_code country_name  \\\n",
       "0     1861060             AS           Asia               JP        Japan   \n",
       "1     1809858             AS           Asia               CN        China   \n",
       "2     1850147             AS           Asia               JP        Japan   \n",
       "3     1814991             AS           Asia               CN        China   \n",
       "4     2077456             OC        Oceania               AU    Australia   \n",
       "\n",
       "  subdivision_iso_code subdivision_name  city_name  metro_code      time_zone  \n",
       "0                  NaN              NaN        NaN         NaN     Asia/Tokyo  \n",
       "1                   44        Guangdong  Guangzhou         NaN  Asia/Shanghai  \n",
       "2                   13            Tōkyō      Tokyo         NaN     Asia/Tokyo  \n",
       "3                  NaN              NaN        NaN         NaN            NaN  \n",
       "4                  NaN              NaN        NaN         NaN            NaN  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdivision_df = pd.DataFrame.from_csv('GeoLite2-City-Locations.csv', index_col=None, encoding='utf8')\n",
    "subdivision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = subdivision_df[['country_name', 'subdivision_name']].dropna().rename(columns={'subdivision_name':'subdivision'})\n",
    "s1['type'] = 'subdivision'\n",
    "s2 = subdivision_df[['country_name', 'subdivision_iso_code']].dropna().rename(columns={'subdivision_iso_code':'subdivision'})\n",
    "s2['type'] = 'subdivision_code'\n",
    "s3 = subdivision_df[['country_name', 'city_name']].dropna().rename(columns={'city_name':'subdivision'})\n",
    "s3['type'] = 'city'\n",
    "alles = pd.concat([s1,s2,s3], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>subdivision</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>subdivision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>subdivision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>subdivision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>subdivision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>Changwat Samut Songkhram</td>\n",
       "      <td>subdivision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name               subdivision         type\n",
       "0        China                 Guangdong  subdivision\n",
       "1        Japan                     Tōkyō  subdivision\n",
       "2    Australia                  Victoria  subdivision\n",
       "3     Thailand                   Bangkok  subdivision\n",
       "4     Thailand  Changwat Samut Songkhram  subdivision"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aland Islands\n"
     ]
    }
   ],
   "source": [
    "unidecode(alles.subdivision.tolist()[1])\n",
    "print unidecode(u'Ãland Islands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_probabilities(old_probability, possible_countries):\n",
    "    if sum(count for _, count in possible_countries) == 0:\n",
    "        # no change to probabilities when there are no contextual clues\n",
    "        return {country: old_probability for country, _ in possible_countries}\n",
    "    \n",
    "    dict_ = {}\n",
    "    for country, count in possible_countries:\n",
    "        new_probability = old_probability\n",
    "        if count == 0:\n",
    "            # only decreases it by a single half if there is no nearby context for it\n",
    "            decrease = (1.0 - new_probability) / 2\n",
    "            new_probability -= decrease\n",
    "        for i in range(count):\n",
    "            # increase probability by half for each context clue in range\n",
    "            increase = (1.0 - new_probability) / 2\n",
    "            new_probability += increase\n",
    "        dict_.update({country: new_probability})\n",
    "    return dict_\n",
    "\n",
    "\n",
    "def context_adjustment(place, possible_countries, probability, text):\n",
    "    print('{} could be in {} with a probability of {} each'.format(place, possible_countries, probability))\n",
    "    tokens = [w for w in nltk.word_tokenize(text) if w.isalpha()]\n",
    "    context = [tokens[i-10:i+10] for i in [ix for ix, i in enumerate(tokens) if i == place]][0]\n",
    "    context.remove(place)\n",
    "    print('{} has a surrounding context of {}'.format(place, context))\n",
    "    print('Recognized locations in the context are {}'.format(filter(lambda x: x in alles.subdivision.tolist(), context)))\n",
    "    context_countries = []\n",
    "    for i in context:\n",
    "        a = alles[alles.subdivision == i]\n",
    "        if not a.empty:\n",
    "            list_ = a.country_name.tolist()\n",
    "            context_countries.extend(list_)\n",
    "            print('{} could refer to {}'.format(i, list_))\n",
    "    context_count = Counter(context_countries)\n",
    "    print('Counts for each context-country are {}'.format(context_count))\n",
    "    ambiguous_country_counts = zip(possible_countries, map(lambda x: context_count[x], possible_countries))\n",
    "    print('Counts for ambiguous countries are {}'.format(ambiguous_country_counts))\n",
    "    new_probabilities = adjust_probabilities(probability, ambiguous_country_counts)\n",
    "    print new_probabilities\n",
    "    print\n",
    "    return new_probabilities\n",
    "    \n",
    "\n",
    "def update_countries_with_regions(entities, countries, text):\n",
    "    subs = pd.DataFrame()\n",
    "    for entity, _ in entities:\n",
    "        a = alles[alles.subdivision == entity]\n",
    "        if not a.empty:\n",
    "            subs = pd.concat([subs, a], ignore_index=True)\n",
    "\n",
    "    if not subs.empty:\n",
    "        no_dupes = subs.drop_duplicates(['country_name', 'subdivision'])\n",
    "        for value_count in no_dupes.subdivision.value_counts().iteritems():\n",
    "            count = value_count[1]\n",
    "            place = value_count[0]\n",
    "            probability = 1.0 / count\n",
    "            if probability == 1.0:\n",
    "                # only one country exists for any probability\n",
    "                probability = 0.8 # correcting for imperfect entity parsing\n",
    "                possible_countries = subs[subs.subdivision == place].country_name.tolist()\n",
    "                country = possible_countries[0]\n",
    "                if country in countries:\n",
    "                    priors = countries[country]\n",
    "                    new_count = priors['count'] + len(possible_countries)\n",
    "                    probability_non_occurrence = (1-priors['probability']) * (1-probability)\n",
    "                    new_probability = 1 - probability_non_occurrence\n",
    "                    countries.update({country: {'count': new_count, 'probability': new_probability}})\n",
    "                else:\n",
    "                    countries.update({country: {'count': len(possible_countries), 'probability': probability}})\n",
    "            else:\n",
    "                # multiple countries exist for a single subdivision\n",
    "                possible_countries = no_dupes[no_dupes.subdivision == place].country_name.tolist()\n",
    "                new_probabilities = context_adjustment(place, possible_countries, probability, text)\n",
    "                for country in possible_countries:\n",
    "                    if country in countries:\n",
    "                        priors = countries[country]\n",
    "                        new_count = priors['count'] + 1\n",
    "                        probability_non_occurrence = (1-priors['probability']) * (1-new_probabilities[country])\n",
    "                        new_probability = 1 - probability_non_occurrence\n",
    "                        countries.update({country: {'count': new_count, 'probability': new_probability}})\n",
    "                    else:\n",
    "                        countries.update({country: {'count': 1, 'probability': new_probabilities[country]}})\n",
    "    return countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = df.ix[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisbon could be in [u'Portugal', u'United States'] with a probability of 0.5 each\n",
      "Lisbon has a surrounding context of [u'incarcerated', u'at', u'Inmate', u'Number', u'FCI', u'Elkton', u'Federal', u'Correctional', u'Institution', u'Box', u'OH', u'and', u'with', u'an', u'address', u'at', u'Courtland', u'Place', u'Laurel']\n",
      "Recognized locations in the context are [u'Elkton', u'Federal', u'Box', u'OH', u'Courtland', u'Place', u'Laurel']\n",
      "Elkton could refer to [u'United States']\n",
      "Federal could refer to [u'Brazil', u'Argentina']\n",
      "Box could refer to [u'United Kingdom', u'Finland']\n",
      "OH could refer to [u'United States']\n",
      "Courtland could refer to [u'United States']\n",
      "Place could refer to [u'France']\n",
      "Laurel could refer to [u'United States']\n",
      "Counts for each context-country are Counter({u'United States': 4, u'Brazil': 1, u'United Kingdom': 1, u'Finland': 1, u'France': 1, u'Argentina': 1})\n",
      "Counts for ambiguous countries are [(u'Portugal', 0), (u'United States', 4)]\n",
      "{u'United States': 0.96875, u'Portugal': 0.25}\n",
      "\n",
      "Maryland could be in [u'United States', u'Australia'] with a probability of 0.5 each\n",
      "Maryland has a surrounding context of [u'Export', u'Privileges', u'On', u'January', u'in', u'the', u'District', u'Court', u'District', u'of', u'Emenike', u'Charles', u'Nwankwoala', u'was', u'convicted', u'of', u'violating', u'Section', u'of']\n",
      "Recognized locations in the context are [u'Export', u'Charles', u'Section']\n",
      "Export could refer to [u'United States']\n",
      "Charles could refer to [u'United Kingdom']\n",
      "Section could refer to [u'United States']\n",
      "Counts for each context-country are Counter({u'United States': 2, u'United Kingdom': 1})\n",
      "Counts for ambiguous countries are [(u'United States', 2), (u'Australia', 0)]\n",
      "{u'United States': 0.875, u'Australia': 0.25}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'Australia': {'count': 1, 'probability': 0.25},\n",
       " u'Nigeria': {'count': 2, 'probability': 1.0},\n",
       " u'Portugal': {'count': 1, 'probability': 0.25},\n",
       " u'United States': {'count': 16, 'probability': 1.0}}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = get_countries(sample.entities)\n",
    "update_countries_with_regions(sample.entities, countries, sample.raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check whether any part of an entity string relates to a country"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
